#!/usr/bin/env python3
"""
å¤šç›¸æœºRealSenseæ•°æ®è·å–æ¨¡å—
æ”¯æŒåŒæ—¶è¿æ¥ä¸‰ä¸ªRealSense D435iç›¸æœºï¼ˆè…•éƒ¨ç›¸æœºã€ä¾§è§†ç›¸æœº1ã€ä¾§è§†ç›¸æœº2ï¼‰
"""

import pyrealsense2 as rs
import numpy as np
import cv2
import time
import threading
from collections import deque
from typing import Dict, Tuple, Optional, List
from rich.console import Console
from rich.logging import RichHandler
import logging

# é…ç½®richæ—¥å¿—
console = Console()
logging.basicConfig(
    level=logging.INFO,
    format="%(message)s",
    datefmt="[%X]",
    handlers=[RichHandler(console=console, rich_tracebacks=True)]
)
logger = logging.getLogger("MultiRealSense")

class MultiRealSenseManager:
    """å¤šRealSenseç›¸æœºç®¡ç†å™¨"""
    
    def __init__(self, camera_configs: Dict[str, Dict] = None, queue_size: int = 10):
        """
        åˆå§‹åŒ–å¤šç›¸æœºç®¡ç†å™¨
        
        Args:
            camera_configs: ç›¸æœºé…ç½®å­—å…¸ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
            {
                "ee_cam": {"serial": "123456789", "width": 640, "height": 480, "fps": 30},
                "side_cam_0": {"serial": "987654321", "width": 640, "height": 480, "fps": 30},
                "side_cam_1": {"serial": "555444333", "width": 640, "height": 480, "fps": 30}
            }
            queue_size: æ¯ä¸ªç›¸æœºçš„å¸§é˜Ÿåˆ—å¤§å°
        """
        self.cameras = {}
        self.pipelines = {}
        self.configs = {}
        self.align_objects = {}
        
        # çº¿ç¨‹å’Œé˜Ÿåˆ—ç®¡ç†
        self.frame_queues = {}  # æ¯ä¸ªç›¸æœºçš„å¸§é˜Ÿåˆ—
        self.camera_threads = {}  # æ¯ä¸ªç›¸æœºçš„çº¿ç¨‹
        self.thread_locks = {}  # æ¯ä¸ªç›¸æœºçš„é”
        self.running = False  # çº¿ç¨‹è¿è¡Œæ ‡å¿—
        self.queue_size = queue_size
        
        # é»˜è®¤é…ç½®
        if camera_configs is None:
            camera_configs = {
                "ee_cam": {"width": 640, "height": 480, "fps": 30},
                "rgb_rs_0": {"width": 640, "height": 480, "fps": 30},
                "rgb_rs_1": {"width": 640, "height": 480, "fps": 30}
            }
        
        self.camera_configs = camera_configs
        self._init_cameras()
        self._start_frame_threads()
    
    def _init_cameras(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç›¸æœº"""
        # è·å–è¿æ¥çš„è®¾å¤‡
        ctx = rs.context()
        devices = ctx.query_devices()
        
        if len(devices) == 0:
            raise RuntimeError("æœªæ£€æµ‹åˆ°RealSenseè®¾å¤‡")
        
        logger.info(f"æ£€æµ‹åˆ° {len(devices)} ä¸ªRealSenseè®¾å¤‡")
        
        # æ‰“å°è®¾å¤‡ä¿¡æ¯
        available_serials = []
        for i, device in enumerate(devices):
            serial = device.get_info(rs.camera_info.serial_number)
            name = device.get_info(rs.camera_info.name)
            available_serials.append(serial)
            logger.info(f"è®¾å¤‡ {i}: {name} (åºåˆ—å·: {serial})")
        
        # å¦‚æœé…ç½®ä¸­æ²¡æœ‰æŒ‡å®šåºåˆ—å·ï¼Œè‡ªåŠ¨åˆ†é…
        camera_names = list(self.camera_configs.keys())
        for i, (camera_name, config) in enumerate(self.camera_configs.items()):
            if "serial" not in config and i < len(available_serials):
                config["serial"] = available_serials[i]
                logger.info(f"è‡ªåŠ¨åˆ†é…ç›¸æœº {camera_name} åˆ°è®¾å¤‡ {available_serials[i]}")
        
        # åˆå§‹åŒ–æ¯ä¸ªç›¸æœº
        for camera_name, config in self.camera_configs.items():
            if "serial" not in config:
                logger.warning(f"è·³è¿‡ç›¸æœº {camera_name}ï¼šæ²¡æœ‰å¯ç”¨çš„è®¾å¤‡")
                continue
                
            try:
                self._init_single_camera(camera_name, config)
                logger.info(f"âœ… ç›¸æœº {camera_name} åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.error(f"âŒ ç›¸æœº {camera_name} åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def _init_single_camera(self, camera_name: str, config: Dict):
        """åˆå§‹åŒ–å•ä¸ªç›¸æœº"""
        # åˆ›å»ºç®¡é“å’Œé…ç½®
        pipeline = rs.pipeline()
        rs_config = rs.config()
        
        # æŒ‡å®šè®¾å¤‡åºåˆ—å·
        rs_config.enable_device(config["serial"])
        
        # é…ç½®æµ
        width = config.get("width", 640)
        height = config.get("height", 480)
        fps = config.get("fps", 30)
        
        rs_config.enable_stream(rs.stream.color, width, height, rs.format.bgr8, fps)
        
        # å¯åŠ¨ç®¡é“
        profile = pipeline.start(rs_config)
        
        # ç›¸æœºåˆå§‹åŒ–åç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œé¿å…å¤šç›¸æœºå†²çª
        time.sleep(0.2)
        
        # è·å–è®¾å¤‡ä¿¡æ¯
        device = profile.get_device()
        
        # åˆå§‹åŒ–å¸§é˜Ÿåˆ—å’Œé”
        self.frame_queues[camera_name] = deque(maxlen=self.queue_size)
        self.thread_locks[camera_name] = threading.Lock()
        
        # ä¿å­˜åˆ°å­—å…¸
        self.pipelines[camera_name] = pipeline
        self.configs[camera_name] = rs_config
        self.cameras[camera_name] = {
            "profile": profile,
            "device": device,
            "config": config
        }
    
    def _start_frame_threads(self):
        """å¯åŠ¨æ‰€æœ‰ç›¸æœºçš„å¸§è·å–çº¿ç¨‹"""
        self.running = True
        for camera_name in self.pipelines.keys():
            thread = threading.Thread(
                target=self._camera_frame_thread, 
                args=(camera_name,), 
                daemon=True,
                name=f"Camera-{camera_name}"
            )
            self.camera_threads[camera_name] = thread
            thread.start()
            logger.info(f"å¯åŠ¨ç›¸æœº {camera_name} å¸§è·å–çº¿ç¨‹")
    
    def _camera_frame_thread(self, camera_name: str):
        """å•ä¸ªç›¸æœºçš„å¸§è·å–çº¿ç¨‹"""
        pipeline = self.pipelines[camera_name]
        
        logger.info(f"ç›¸æœº {camera_name} çº¿ç¨‹å¼€å§‹è¿è¡Œ")
        
        while self.running:
            try:
                # ä½¿ç”¨poll_for_frameséé˜»å¡è·å–å¸§
                frames = pipeline.poll_for_frames()
                
                if frames:
                    # è·å–å½©è‰²å¸§
                    color_frame = frames.get_color_frame()
                    
                    if color_frame:
                        # è½¬æ¢ä¸ºnumpyæ•°ç»„
                        color_image = np.asanyarray(color_frame.get_data())
                        
                        # çº¿ç¨‹å®‰å…¨åœ°æ·»åŠ åˆ°é˜Ÿåˆ—
                        with self.thread_locks[camera_name]:
                            self.frame_queues[camera_name].append(color_image)
                
                # çŸ­æš‚ä¼‘çœ é¿å…è¿‡åº¦å ç”¨CPU
                time.sleep(0.001)
                
            except Exception as e:
                if self.running:  # åªåœ¨è¿è¡Œæ—¶è®°å½•é”™è¯¯
                    logger.warning(f"ç›¸æœº {camera_name} çº¿ç¨‹é”™è¯¯: {e}")
                time.sleep(0.01)
        
        logger.info(f"ç›¸æœº {camera_name} çº¿ç¨‹ç»“æŸ")
    
    def get_frame(self, camera_name: str) -> Optional[np.ndarray]:
        """
        ä»é˜Ÿåˆ—è·å–æŒ‡å®šç›¸æœºçš„æœ€æ–°å½©è‰²å¸§
        
        Args:
            camera_name: ç›¸æœºåç§°
            
        Returns:
            color_image æˆ– None
        """
        if camera_name not in self.frame_queues:
            return None
        
        try:
            # çº¿ç¨‹å®‰å…¨åœ°ä»é˜Ÿåˆ—è·å–æœ€æ–°å¸§
            with self.thread_locks[camera_name]:
                if len(self.frame_queues[camera_name]) > 0:
                    # è·å–æœ€æ–°çš„å¸§ï¼ˆé˜Ÿåˆ—å³ç«¯ï¼‰
                    return self.frame_queues[camera_name][-1]
                else:
                    return None
            
        except Exception as e:
            return None
    
    def get_all_frames(self) -> Dict[str, Optional[np.ndarray]]:
        """
        è·å–æ‰€æœ‰ç›¸æœºçš„å¸§æ•°æ®
        
        Returns:
            å­—å…¸ï¼Œkeyä¸ºç›¸æœºåç§°ï¼Œvalueä¸ºcolor_image
        """
        results = {}
        for camera_name in self.pipelines.keys():
            results[camera_name] = self.get_frame(camera_name)
        return results
    
    def get_color_frames_for_lerobot(self) -> Dict[str, Optional[np.ndarray]]:
        """
        è·å–æ‰€æœ‰ç›¸æœºçš„å½©è‰²å¸§ï¼Œæ ¼å¼é€‚é…lerobotæ•°æ®é›†
        
        Returns:
            å­—å…¸ï¼Œkeyä¸ºlerobotæ ¼å¼çš„åç§°ï¼Œvalueä¸ºRGBå›¾åƒï¼ˆHWCæ ¼å¼ï¼‰
        """
        results = {}
        
        # æ˜ å°„ç›¸æœºåç§°åˆ°lerobotæ ¼å¼
        name_mapping = {
            "ee_cam": "observation.images.ee_cam",
            "rgb_rs_0": "observation.images.rgb_rs_0", 
            "rgb_rs_1": "observation.images.rgb_rs_1"
        }
        
        for camera_name in self.pipelines.keys():
            color_image = self.get_frame(camera_name)
            if color_image is not None:
                # è½¬æ¢BGRåˆ°RGB
                rgb_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)
                # è½¬æ¢ä¸ºCHWæ ¼å¼ (3, H, W)
                rgb_image_chw = np.transpose(rgb_image, (2, 0, 1))
                
                # ä½¿ç”¨lerobotæ ¼å¼çš„é”®å
                lerobot_key = name_mapping.get(camera_name, f"observation.images.{camera_name}")
                results[lerobot_key] = rgb_image_chw
            else:
                lerobot_key = name_mapping.get(camera_name, f"observation.images.{camera_name}")
                results[lerobot_key] = None
        
        return results
    
    def get_intrinsics(self, camera_name: str) -> Optional[Dict]:
        """è·å–æŒ‡å®šç›¸æœºçš„å†…å‚"""
        if camera_name not in self.cameras:
            return None
        
        try:
            profile = self.cameras[camera_name]["profile"]
            color_stream = profile.get_stream(rs.stream.color)
            intrinsics = color_stream.as_video_stream_profile().get_intrinsics()
            
            return {
                'width': intrinsics.width,
                'height': intrinsics.height,
                'fx': intrinsics.fx,
                'fy': intrinsics.fy,
                'cx': intrinsics.ppx,
                'cy': intrinsics.ppy,
                'model': intrinsics.model,
                'coeffs': intrinsics.coeffs
            }
        except Exception as e:
            logger.warning(f"è·å–ç›¸æœº {camera_name} å†…å‚å¤±è´¥: {e}")
        
        return None
    
    def save_frames(self, prefix: str = "capture"):
        """ä¿å­˜æ‰€æœ‰ç›¸æœºçš„å½“å‰å¸§"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        
        for camera_name in self.pipelines.keys():
            color_image = self.get_frame(camera_name)
            if color_image is not None:
                cv2.imwrite(f"{prefix}_{camera_name}_color_{timestamp}.png", color_image)
        
        logger.info(f"ğŸ’¾ æ‰€æœ‰ç›¸æœºå¸§å·²ä¿å­˜: {prefix}_*_{timestamp}")
    
    def get_camera_count(self) -> int:
        """è·å–æˆåŠŸåˆå§‹åŒ–çš„ç›¸æœºæ•°é‡"""
        return len(self.pipelines)
    
    def get_camera_names(self) -> List[str]:
        """è·å–æ‰€æœ‰ç›¸æœºåç§°"""
        return list(self.pipelines.keys())
    
    def get_queue_status(self) -> Dict[str, int]:
        """è·å–å„ç›¸æœºé˜Ÿåˆ—ä¸­çš„å¸§æ•°"""
        status = {}
        for camera_name in self.frame_queues.keys():
            with self.thread_locks[camera_name]:
                status[camera_name] = len(self.frame_queues[camera_name])
        return status
    
    def stop_all(self):
        """åœæ­¢æ‰€æœ‰ç›¸æœºå’Œçº¿ç¨‹"""
        # é¦–å…ˆåœæ­¢çº¿ç¨‹
        self.running = False
        logger.info("æ­£åœ¨åœæ­¢æ‰€æœ‰ç›¸æœºçº¿ç¨‹...")
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹ç»“æŸ
        for camera_name, thread in self.camera_threads.items():
            if thread.is_alive():
                thread.join(timeout=2.0)
                if thread.is_alive():
                    logger.warning(f"ç›¸æœº {camera_name} çº¿ç¨‹æœªèƒ½æ­£å¸¸ç»“æŸ")
                else:
                    logger.info(f"ç›¸æœº {camera_name} çº¿ç¨‹å·²ç»“æŸ")
        
        # åœæ­¢æ‰€æœ‰ç®¡é“
        for camera_name, pipeline in self.pipelines.items():
            try:
                pipeline.stop()
                logger.info(f"ç›¸æœº {camera_name} ç®¡é“å·²åœæ­¢")
            except Exception as e:
                logger.warning(f"åœæ­¢ç›¸æœº {camera_name} ç®¡é“å¤±è´¥: {e}")
        
        # æ¸…ç†æ‰€æœ‰èµ„æº
        self.pipelines.clear()
        self.configs.clear()
        self.cameras.clear()
        self.frame_queues.clear()
        self.camera_threads.clear()
        self.thread_locks.clear()


def test_multi_cameras():
    """æµ‹è¯•å¤šç›¸æœºåŠŸèƒ½"""
    try:
        # åˆ›å»ºå¤šç›¸æœºç®¡ç†å™¨
        manager = MultiRealSenseManager()
        
        if manager.get_camera_count() == 0:
            logger.error("æ²¡æœ‰æˆåŠŸåˆå§‹åŒ–ä»»ä½•ç›¸æœº")
            return
        
        logger.info(f"æˆåŠŸåˆå§‹åŒ– {manager.get_camera_count()} ä¸ªç›¸æœº")
        logger.info(f"ç›¸æœºåˆ—è¡¨: {manager.get_camera_names()}")
        
        # åˆ›å»ºæ˜¾ç¤ºçª—å£
        camera_names = manager.get_camera_names()
        for camera_name in camera_names:
            cv2.namedWindow(f'{camera_name}', cv2.WINDOW_AUTOSIZE)
        
        fps_count = 0
        start_time = time.time()
        
        while True:
            # è·å–æ‰€æœ‰ç›¸æœºçš„å¸§
            all_frames = manager.get_all_frames()
            
            # ç»Ÿè®¡æœ‰æ•ˆå¸§æ•°
            valid_frames = 0
            
            # æ˜¾ç¤ºæ¯ä¸ªç›¸æœºçš„å›¾åƒ
            for camera_name, color_image in all_frames.items():
                if color_image is not None:
                    valid_frames += 1
                    # æ˜¾ç¤ºå½©è‰²å›¾åƒ
                    cv2.imshow(f'{camera_name}', color_image)
                else:
                    # å¦‚æœæ²¡æœ‰è·å–åˆ°å¸§ï¼Œæ˜¾ç¤ºé»‘å±
                    blank_img = np.zeros((480, 640, 3), dtype=np.uint8)
                    cv2.putText(blank_img, f'{camera_name} - No Frame', (50, 240), 
                              cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                    cv2.imshow(f'{camera_name}', blank_img)
            
            # è®¡ç®—FPS
            fps_count += 1
            if fps_count % 30 == 0:
                end_time = time.time()
                fps = 30 / (end_time - start_time)
                queue_status = manager.get_queue_status()
                queue_info = ", ".join([f"{name}:{count}" for name, count in queue_status.items()])
                logger.info(f"FPS: {fps:.2f}, æœ‰æ•ˆå¸§: {valid_frames}/{len(camera_names)}, é˜Ÿåˆ—: [{queue_info}]")
                start_time = time.time()
            
            # å¤„ç†æŒ‰é”®
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q') or key == 27:  # qæˆ–ESCé€€å‡º
                break
            elif key == ord('s'):  # sä¿å­˜å›¾åƒ
                manager.save_frames()
        
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
    finally:
        # æ¸…ç†èµ„æº
        if 'manager' in locals():
            manager.stop_all()
        cv2.destroyAllWindows()
        logger.info("æµ‹è¯•ç»“æŸ")


if __name__ == "__main__":
    test_multi_cameras()